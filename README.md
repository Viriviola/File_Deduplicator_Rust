# File_Depduplicator_Rust

# ğŸ§  Intelligent File Deduplicator (Rust)

This is a beginner-friendly Rust project that scans a directory and detects duplicate files based on content. It safely quarantines duplicates and generates detailed reports in JSON or HTML format.

---

## âœ¨ Features

* âœ… **Multi-Algorithm Hashing** (SHA-256 implemented)
* ğŸš€ **Parallel Processing** using Rayon for fast hashing
* ğŸ§° **Advanced Filtering**: by file size, extension, date modified, and name patterns
* ğŸ›¡ï¸ **Safe Quarantine System** before deletion
* ğŸ“Š **Detailed Reports**: JSON + HTML with space-saving stats
* ğŸ§ª **Unit Tests** included (in `tests/` folder)

---

## ğŸ“ Project Structure

```
file_deduplicator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs             # CLI entry point
â”‚   â”œâ”€â”€ lib.rs              # Library module declarations
â”‚   â”œâ”€â”€ cli.rs              # Command-line argument parser
â”‚   â”œâ”€â”€ scan.rs             # File collection logic
â”‚   â”œâ”€â”€ filter.rs           # File filtering by size, extension, etc.
â”‚   â”œâ”€â”€ hash.rs             # File hashing (SHA-256)
â”‚   â”œâ”€â”€ group.rs            # Grouping and duplicate detection
â”‚   â”œâ”€â”€ quarantine.rs       # Safe quarantine of duplicates
â”‚   â”œâ”€â”€ report.rs           # JSON/HTML report generation
â”‚   â””â”€â”€ models.rs           # Data structures (Report, DuplicateGroup)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ tests.rs            # Integration tests
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ report.html         # HTML report template (Tera)
â”œâ”€â”€ Cargo.toml              # Dependencies and metadata
â””â”€â”€ README.md               # This file
```

---

## âš™ï¸ Usage

### ğŸ› ï¸ Build

```bash
cargo build
```

### ğŸš€ Run

```bash
cargo run -- <folder_path> --report html --quarantine true
```

Example:

```bash
cargo run -- E:/File_Dedup_Rust/input --report json
```

### ğŸ“„ CLI Options

| Flag           | Description                     | Default    |
| -------------- | ------------------------------- | ---------- |
| `path`         | Path to folder to scan          | (Required) |
| `--report`     | Report format: `json` or `html` | `json`     |
| `--quarantine` | Whether to move duplicates      | `true`     |

---

## ğŸ§ª Testing

```bash
cargo test
```

Tests include:

* File filtering
* Duplicate grouping
* Quarantine logic
* Report generation (JSON & HTML)

---

## ğŸ›  Dependencies

The following crates are used:

| Crate        | Purpose                       |
| ------------ | ----------------------------- |
| `rayon`      | Parallel file hashing         |
| `sha2`       | SHA-256 file hashing          |
| `clap`       | Command-line interface        |
| `serde`      | Serialization for reports     |
| `serde_json` | JSON report generation        |
| `tera`       | HTML report templating        |
| `walkdir`    | Recursive directory traversal |
| `tempfile`   | Temp dirs in unit tests       |

---

## ğŸ“Š Sample Output (JSON)

```json
{
  "scanned": 10,
  "duplicates_found": 2,
  "space_savings": 2048,
  "space_savings_size": "2.00 KB",
  "duplicate_groups": [
    {
      "hash": "...",
      "files": ["a.txt", "b.txt"]
    }
  ]
}
```

---

## ğŸ“Œ Notes

* Only SHA-256 is currently used; Blake3 and xxHash can be added.
* Filters are fixed in code (`.txt`, `.rs`, size > 0) â€” can be made dynamic via CLI.
* HTML report depends on the `templates/report.html` file using Tera.

---

## ğŸ’¡ Future Improvements

* Configurable hashing algorithm via CLI
* GUI front-end for drag-and-drop usage
* More flexible filtering from CLI
* Real-time progress bar for hashing

---

## ğŸ‘¶ Beginner-Friendly Rust

This project intentionally uses **very simple** Rust patterns and avoids complex abstractions to help new Rustaceans get comfortable with real-world project structure.

---

## ğŸ§‘â€ğŸ’» Author

* Built as part of a guided Rust learning journey âœ¨
* Contributions and suggestions welcome!

